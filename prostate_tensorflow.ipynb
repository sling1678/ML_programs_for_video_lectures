{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prostate_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxwNhJfVZMaabqU+t3/qCB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sling1678/ML_programs_for_video_lectures/blob/main/prostate_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem\n",
        "Stamey et al (1989), \"Prostate specific antigen (PSA) in the diagnosis and treatment of adenocarcinoma of the prostate II radical prostatectomy treated patients\", Journal of Urology, vol 16, 1076-1083. A copy of Abstract here, https://pubmed.ncbi.nlm.nih.gov/2468795/. \n",
        "\n",
        "The statistical learning problem is to predict y = (log of PSA) from 8 other variables.\n",
        "\n",
        "x_1 = log of cancer volume (lcavol); NUMERICAL\n",
        "\n",
        "x_2 = log of prostate weight (lweight); NUMERICAL\n",
        "\n",
        "x_3 = age (age); NUMERICAL\n",
        "\n",
        "x_4 = log of amount of benign prostatic hyperplasia (lbph); NUMERICAL\n",
        "\n",
        "x_5 = seminal vesicle invasion (svi); INTEGER_CATEGORICAL\n",
        "\n",
        "x_6 = log of capsular penetration (lcp); NUMERICAL\n",
        "\n",
        "x_7 = Gleason score (gleason); INTEGER_CATEGORICAL\n",
        "\n",
        "x_8 = percent of Gleason scores 4 or 5 (pgg45). NUMERICAL"
      ],
      "metadata": {
        "id": "g26D8iYLovYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#IMPORTS\n",
        "import os # for environment\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn.model_selection  # we might use train_test_split to create validation set for hyperparameter(s)\n",
        "\n",
        "#-----------------"
      ],
      "metadata": {
        "id": "-jO0TMF5t0ps"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GLOBALS\n",
        "BATCH_SIZE=16\n",
        "EPOCHS=2000\n",
        "TRIALS=30\n",
        "EXPERIMENTING = False # Make it False for final"
      ],
      "metadata": {
        "id": "2KgPDpSUQOpt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------- Seed random behavior to get consistent results\n",
        "def set_seeds(seed):\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  random.seed(seed)\n",
        "  tf.random.set_seed(seed)\n",
        "  np.random.seed(seed)\n",
        "    \n",
        "def set_global_determinism(seed):\n",
        "  \n",
        "  random_state =  sklearn.utils.check_random_state(seed)\n",
        "  set_seeds(seed=seed)\n",
        "\n",
        "  os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "  os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "    \n",
        "  tf.config.threading.set_inter_op_parallelism_threads(1)\n",
        "  tf.config.threading.set_intra_op_parallelism_threads(1)\n",
        "  return random_state\n",
        "\n",
        "# Call the above function with seed value \n",
        "\n",
        "if EXPERIMENTING:\n",
        "  random_state = set_global_determinism(seed=43) # for sklearn\n",
        "else:\n",
        "  seed = np.random.randint(3, 333333333)\n",
        "  random_state = set_global_determinism(seed)"
      ],
      "metadata": {
        "id": "GNOfD7liQROM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataframes for this project\n",
        "DATA_URL = \"https://hastie.su.domains/ElemStatLearn/datasets/prostate.data\"\n",
        "\n",
        "TARGET = 'lpsa'\n",
        "TRAINING_SET_SELECTOR = ['train']\n",
        "NUMERICAL_FEATURES = ['lcavol', 'lweight', 'age', 'lbph',  'lcp',  'pgg45']\n",
        "STRING_CATEGORICAL_FEATURES = []\n",
        "INTEGER_CATEGORICAL_FEATURES = ['svi','gleason',]\n",
        "FEATURES = NUMERICAL_FEATURES + STRING_CATEGORICAL_FEATURES + INTEGER_CATEGORICAL_FEATURES\n",
        "\n",
        "#-------------------GET DATAFRAME\n",
        "df = pd.read_csv(DATA_URL, sep='\\t')\n",
        "#-------------------CHECK IT\n",
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "cWPztjVwuHOu",
        "outputId": "cef8f118-070c-4f51-98fd-2469cf51ee4b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0    lcavol   lweight  age      lbph  svi       lcp  gleason  \\\n",
              "0           1 -0.579818  2.769459   50 -1.386294    0 -1.386294        6   \n",
              "1           2 -0.994252  3.319626   58 -1.386294    0 -1.386294        6   \n",
              "2           3 -0.510826  2.691243   74 -1.386294    0 -1.386294        7   \n",
              "\n",
              "   pgg45      lpsa train  \n",
              "0      0 -0.430783     T  \n",
              "1      0 -0.162519     T  \n",
              "2     20 -0.162519     T  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bdfa3276-991c-4d69-bb8f-33ac4509eb88\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>lcavol</th>\n",
              "      <th>lweight</th>\n",
              "      <th>age</th>\n",
              "      <th>lbph</th>\n",
              "      <th>svi</th>\n",
              "      <th>lcp</th>\n",
              "      <th>gleason</th>\n",
              "      <th>pgg45</th>\n",
              "      <th>lpsa</th>\n",
              "      <th>train</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.579818</td>\n",
              "      <td>2.769459</td>\n",
              "      <td>50</td>\n",
              "      <td>-1.386294</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.386294</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.430783</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.994252</td>\n",
              "      <td>3.319626</td>\n",
              "      <td>58</td>\n",
              "      <td>-1.386294</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.386294</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.162519</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.510826</td>\n",
              "      <td>2.691243</td>\n",
              "      <td>74</td>\n",
              "      <td>-1.386294</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.386294</td>\n",
              "      <td>7</td>\n",
              "      <td>20</td>\n",
              "      <td>-0.162519</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bdfa3276-991c-4d69-bb8f-33ac4509eb88')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bdfa3276-991c-4d69-bb8f-33ac4509eb88 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bdfa3276-991c-4d69-bb8f-33ac4509eb88');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I. Get Data and Prepare Pandas DataFrames"
      ],
      "metadata": {
        "id": "MNCe3HG-tvFN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyMNaYrMtgY7",
        "outputId": "02d0156c-6462-42e6-80e2-470161ee17ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes: train (53, 9), test (30, 9), validation (14, 9)\n",
            "first three rows of training data are:\n",
            "     lcavol   lweight  age      lbph  svi       lcp  gleason  pgg45      lpsa\n",
            "0  1.477049  2.998229   67 -1.386294    0 -1.386294        7      5  1.348073\n",
            "1  1.781709  3.451574   63  0.438255    0  1.178655        7     60  1.713798\n",
            "2  1.562346  3.709907   60  1.695616    0  0.810930        7     30  3.587677\n",
            "Shapes: train (53, 9), test (30, 9), validation (14, 9)\n",
            "first three rows of training data are:\n",
            "     lcavol   lweight  age      lbph  svi       lcp  gleason  pgg45      lpsa\n",
            "0  0.285179  4.090169   65  1.962908    0 -0.798508        6      0  1.924249\n",
            "1  0.463734  3.764682   49  1.423108    0 -1.386294        6      0  2.794228\n",
            "2  2.010895  4.433789   72  2.122262    0  0.500775        7     60  3.392829\n"
          ]
        }
      ],
      "source": [
        "def prepare_Xy_dataframes(df, features, target, training_set_selector=None, test_frac=0.2, val_frac=0.2, verbose=0):\n",
        "  df = df.copy()\n",
        "  if training_set_selector is not None:\n",
        "    df = df[features + [target] + training_set_selector] # this will drop fictitious columns that show up in the downloaded file\n",
        "    train_df = df[df['train']=='T'].copy() # We will need a validation set for hyperparameters - we omit this step\n",
        "    test_df = df[df['train'] != 'T'].copy()\n",
        "    train_df.drop('train',axis=1, inplace=True)\n",
        "    test_df.drop('train',axis=1, inplace=True)\n",
        "  else:\n",
        "    print(features)\n",
        "    columns = features + [target]\n",
        "    print(columns)\n",
        "    df = df[columns]\n",
        "    train_df, test_df = sklearn.model_selection.train_test_split(df, test_size=test_frac, random_state=random_state)\n",
        "  \n",
        "  train_df, val_df = sklearn.model_selection.train_test_split(train_df, test_size=val_frac)\n",
        "  train_df.reset_index(drop=True, inplace=True)\n",
        "  test_df.reset_index(drop=True, inplace=True)\n",
        "  val_df.reset_index(drop=True, inplace=True)\n",
        "  \n",
        "  if verbose >= 1:\n",
        "    print(f\"Shapes: train {train_df.shape}, test {test_df.shape}, validation {val_df.shape}\")\n",
        "  if verbose > 1:\n",
        "    print(f\"first three rows of training data are:\\n{train_df.head(3)}\")\n",
        "\n",
        "  return train_df, test_df, val_df\n",
        "\n",
        "#----------------------   Check if randomness is absent; \n",
        "train_df, test_df, val_df = prepare_Xy_dataframes(df, features=FEATURES, target=TARGET, \n",
        "  training_set_selector=TRAINING_SET_SELECTOR, test_frac=0.2, verbose=2)\n",
        "train_df, test_df, val_df = prepare_Xy_dataframes(df, features=FEATURES, target=TARGET, \n",
        "  training_set_selector=TRAINING_SET_SELECTOR, test_frac=0.2, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_a_batch(dataset):\n",
        "  for feature_batch, target_batch in dataset.take(1):\n",
        "    print(f\"Features are: {list(feature_batch.keys())}\")\n",
        "    print(f\"A batch of lcavol: {feature_batch['lcavol']}\" )\n",
        "    print(f\"A batch of lweight: {feature_batch['lweight']}\")\n",
        "    print(f\"A batch of targets: {target_batch}\")  \n",
        "\n",
        "def convert_df_to_Xyds(df, target, shuffle=True, batch_size=16, verbose=0):\n",
        "  df = df.copy()\n",
        "  y_df = df.pop(target) # now df is X_df only\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(df), y_df)) # Keep the column names as keys\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(df))\n",
        "  ds = ds.batch(batch_size)\n",
        "  if verbose!=0:\n",
        "    print_a_batch(ds)\n",
        "  return ds\n",
        "\n",
        "#---------------------------\n",
        "if EXPERIMENTING:\n",
        "  train_shuffle=False\n",
        "else:\n",
        "  train_shuffle=True\n",
        "print(\"Training Data:\")\n",
        "train_dataset = convert_df_to_Xyds(train_df, target=TARGET, shuffle=train_shuffle, batch_size=BATCH_SIZE, verbose=1)\n",
        "test_dataset = convert_df_to_Xyds(test_df, target=TARGET, shuffle=False, batch_size=BATCH_SIZE, verbose=0)\n",
        "val_dataset = convert_df_to_Xyds(val_df, target=TARGET, shuffle=train_shuffle, batch_size=BATCH_SIZE, verbose=1)\n",
        "#------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwBAMBuW8LBV",
        "outputId": "1ab8783c-90ed-48dd-d914-56738949c222"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data:\n",
            "Features are: ['lcavol', 'lweight', 'age', 'lbph', 'svi', 'lcp', 'gleason', 'pgg45']\n",
            "A batch of lcavol: [ 2.72785283  0.18232156  1.4861397   1.6639261   0.62057649  2.99922616\n",
            " -1.34707365  0.46373402 -0.41551544  1.5623463  -0.51082562  1.46787435\n",
            "  2.77570885 -0.99425227  2.010895    2.40964417]\n",
            "A batch of lweight: [3.995445 3.825375 3.409496 3.392829 3.141995 3.849083 3.598681 3.764682\n",
            " 3.516013 3.69511  2.691243 3.070376 3.524889 3.319626 4.433789 3.37588 ]\n",
            "A batch of targets: [ 2.5687881  1.5993876  2.5217206  2.5533438  2.2975726  3.2752562\n",
            "  1.2669476  2.7942279  1.4701758  3.993603  -0.1625189  3.5160131\n",
            "  2.8535925 -0.1625189  3.3928291  1.8946169]\n",
            "Features are: ['lcavol', 'lweight', 'age', 'lbph', 'svi', 'lcp', 'gleason', 'pgg45']\n",
            "A batch of lcavol: [-1.2039728  -0.01005034  2.80759383  0.75141609  3.30284926 -0.54472718\n",
            "  2.6483002   1.42310833  1.0612565   3.14113048  2.02419307  1.66013103\n",
            "  0.45742485  1.2669476 ]\n",
            "A batch of lweight: [3.282789 3.216874 4.718052 3.432373 3.51898  3.37588  3.582129 3.657131\n",
            " 3.851211 3.263849 3.731699 4.234831 2.374906 4.280132]\n",
            "A batch of targets: [-0.1625189  2.0476928  3.9843437  0.3715636  3.6309855  1.6956156\n",
            "  3.4578927  2.1575593  2.8124102  3.3375474  3.6800909  2.677591\n",
            "  2.1916535  2.7180005]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the Input Layer\n",
        " "
      ],
      "metadata": {
        "id": "3KIsB0W7DuIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_numerical_feature(feature, name, dataset):\n",
        "  \"\"\"\n",
        "  from https://keras.io/examples/structured_data/structured_data_classification_from_scratch/\n",
        "  \"\"\"\n",
        "  # Create a Normalization layer for our feature\n",
        "  normalizer = tf.keras.layers.Normalization()\n",
        "\n",
        "  # Prepare a Dataset that only yields our feature\n",
        "  feature_ds = dataset.map(lambda x, y: x[name])\n",
        "  feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
        "\n",
        "  # Learn the statistics of the data\n",
        "  normalizer.adapt(feature_ds)\n",
        "\n",
        "  # Normalize the input feature\n",
        "  encoded_feature = normalizer(feature)\n",
        "  return encoded_feature\n",
        "\n",
        "def encode_categorical_feature(feature, name, dataset, is_string):\n",
        "    lookup_class = tf.keras.layers.StringLookup if is_string else tf.keras.layers.IntegerLookup\n",
        "    # Create a lookup layer which will turn strings into integer indices\n",
        "    lookup = lookup_class(output_mode=\"binary\")\n",
        "\n",
        "    # Prepare a Dataset that only yields our feature\n",
        "    feature_ds = dataset.map(lambda x, y: x[name])\n",
        "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
        "\n",
        "    # Learn the set of possible string values and assign them a fixed integer index\n",
        "    lookup.adapt(feature_ds)\n",
        "\n",
        "    # Turn the string input into integer indices\n",
        "    encoded_feature = lookup(feature)\n",
        "    return encoded_feature\n",
        "\n",
        "#-----------------------------------------------\n",
        "numerical_inputs = [tf.keras.Input(shape=(1,), name=feature) for feature in NUMERICAL_FEATURES]\n",
        "str_categorical_inputs = [tf.keras.Input(shape=(1,), name=feature) for feature in STRING_CATEGORICAL_FEATURES]\n",
        "int_categorical_inputs = [tf.keras.Input(shape=(1,), name=feature) for feature in INTEGER_CATEGORICAL_FEATURES]\n",
        "\n",
        "inputs = numerical_inputs + str_categorical_inputs + int_categorical_inputs\n",
        "output_of_processing_layers = tf.keras.layers.concatenate(\n",
        "    [encode_numerical_feature(\n",
        "        input, name, train_dataset\n",
        "    ) for input, name in zip(numerical_inputs, NUMERICAL_FEATURES)\n",
        "    ]\n",
        "    +\n",
        "    [encode_categorical_feature(\n",
        "        input, name, train_dataset, is_string=True \n",
        "    ) for input, name in zip(str_categorical_inputs, STRING_CATEGORICAL_FEATURES)\n",
        "    ]\n",
        "    +\n",
        "    [encode_categorical_feature(\n",
        "        input, name, train_dataset, is_string=False \n",
        "    ) for input, name in zip(int_categorical_inputs, INTEGER_CATEGORICAL_FEATURES)\n",
        "    ]        \n",
        ")\n"
      ],
      "metadata": {
        "id": "am2UgkxzDGyy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete the model by acting on the data fed in the network after preprocessing layers\n",
        "output = tf.keras.layers.Dense(1, activation=\"linear\")(output_of_processing_layers)\n",
        "model = tf.keras.Model(inputs, output)\n",
        "model.compile(\"adam\", \"mean_squared_error\", metrics=[\"mean_squared_error\"])\n",
        "# `rankdir='LR'` is to make the graph horizontal.\n",
        "if False:\n",
        "  tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")\n",
        "if False:\n",
        "  model.summary()"
      ],
      "metadata": {
        "id": "s85wGlPLf_bf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make a Trial Run"
      ],
      "metadata": {
        "id": "DihiZse8gYLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset, epochs=EPOCHS, validation_data=val_dataset, verbose=0) \n",
        "print(model.trainable_weights)\n",
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  #plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Error')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "plot_loss(model.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "r7CT3xJ0-0LD",
        "outputId": "62f4ee6b-b69c-40d7-c9eb-36860d59bdc0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Variable 'dense/kernel:0' shape=(8, 1) dtype=float32, numpy=\n",
            "array([[ 0.7451132 ],\n",
            "       [ 0.388647  ],\n",
            "       [-0.21506254],\n",
            "       [ 0.2198226 ],\n",
            "       [ 0.32132685],\n",
            "       [-0.36436936],\n",
            "       [-0.11555722],\n",
            "       [ 0.4105723 ]], dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([2.4529214], dtype=float32)>]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare the values obtained to Table 3.2 of Elem Stat Learning:\n",
        "\n",
        "w_esl = [0.68, 0.26, -0.14, 0.21, 0.31, -0.29, -0.02, 0.27],\n",
        "\n",
        "w_here = [0.89, 0.27, -0.20, 0.25, 0.20, -0.34, -0.12, 0.36].\n",
        "\n",
        "b_esl = 2.46\n",
        "\n",
        "b_here = 2.45\n"
      ],
      "metadata": {
        "id": "i33wntJnMs1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "  model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "aXKeEZWNen3R"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction Problem\n",
        "if False:\n",
        "  y_pred = model.predict(test_dataset)\n",
        "  for item in y_pred:\n",
        "    print(item)"
      ],
      "metadata": {
        "id": "PZc70R0vN-js"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "  train_dataset=train_dataset.concatenate(val_dataset)\n",
        "  model.fit(train_dataset, epochs=EPOCHS, validation_data=train_dataset, verbose=0)\n",
        "  print(model.evaluate(train_dataset))\n",
        "  print(model.evaluate(test_dataset))"
      ],
      "metadata": {
        "id": "dfOStzv9U99z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full Simulation\n",
        "## Full simulation must determine variances in the weights also. For that we will repeat experiment 30 times and report mean and standard error in weight values"
      ],
      "metadata": {
        "id": "QhcVSvu3gg0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def run_experiment(train_dataset, test_dataset, epochs=5, val_dataset=None, trials=30, verbose=0):\n",
        "  err_in = [] # these are in_sample errorr in each trial\n",
        "  err_out = [] # out of sample errors\n",
        "  weights = []\n",
        "  biases = []\n",
        "  if val_dataset is not None:\n",
        "    train_dataset = train_dataset.concatenate(val_dataset) # train on full training set\n",
        "  else:\n",
        "    validation_data = train_dataset\n",
        "  for trial in range(trials):\n",
        "    model.fit(train_dataset, epochs=epochs, validation_data=validation_data, verbose=verbose)\n",
        "    e_in = model.evaluate(train_dataset)[-1]\n",
        "    e_out = model.evaluate(test_dataset)[-1]\n",
        "    w = model.trainable_weights[0].numpy().flatten()\n",
        "    b = model.trainable_weights[1].numpy().flatten()\n",
        "    err_in.append(e_in)\n",
        "    err_out.append(e_out)\n",
        "    weights.append(w)\n",
        "    biases.append(b)\n",
        "  \n",
        "  err_in_mean, err_in_stderr = np.mean(err_in), np.std(err_in)/np.sqrt(trials)\n",
        "  err_out_mean, err_out_stderr = np.mean(err_out), np.std(err_out)/np.sqrt(trials)\n",
        "  weights_mean, weights_stderr = np.mean(weights,axis=0), np.std(weights, axis=0)/np.sqrt(trials)    \n",
        "  bias_mean, bias_stderr = np.mean(biases), np.std(biases)/np.sqrt(trials)\n",
        "  results = (   \n",
        "      (err_in_mean, err_in_stderr),\n",
        "      (err_out_mean, err_out_stderr),\n",
        "      (weights_mean, weights_stderr),\n",
        "      (bias_mean, bias_stderr)\n",
        "  )\n",
        "  return results\n",
        "\n",
        "\n",
        "#-----------------------------------\n",
        "\n",
        "full_training_dataset = train_dataset.concatenate(val_dataset)\n",
        "results = run_experiment(full_training_dataset, test_dataset, epochs=EPOCHS, val_dataset=None, trials=TRIALS, verbose=0)\n",
        "err_in, err_out, weights, bias = results\n",
        "print(err_in)\n",
        "print(err_out)\n",
        "print(weights)\n",
        "print(bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5D7cu3zWDv2",
        "outputId": "d7e0acb4-e2ae-4885-b8f6-45d80814dd73"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4393 - mean_squared_error: 0.4393\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5192 - mean_squared_error: 0.5192\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4393 - mean_squared_error: 0.4393\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5244 - mean_squared_error: 0.5244\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4393 - mean_squared_error: 0.4393\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5260 - mean_squared_error: 0.5260\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4406 - mean_squared_error: 0.4406\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5309 - mean_squared_error: 0.5309\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4395 - mean_squared_error: 0.4395\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5193 - mean_squared_error: 0.5193\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4397 - mean_squared_error: 0.4397\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5220 - mean_squared_error: 0.5220\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4396 - mean_squared_error: 0.4396\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5245 - mean_squared_error: 0.5245\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4395 - mean_squared_error: 0.4395\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5181 - mean_squared_error: 0.5181\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4394 - mean_squared_error: 0.4394\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5238 - mean_squared_error: 0.5238\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4395 - mean_squared_error: 0.4395\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5258 - mean_squared_error: 0.5258\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4393 - mean_squared_error: 0.4393\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5209 - mean_squared_error: 0.5209\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4400 - mean_squared_error: 0.4400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5283 - mean_squared_error: 0.5283\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4400 - mean_squared_error: 0.4400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5234 - mean_squared_error: 0.5234\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4393 - mean_squared_error: 0.4393\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5236 - mean_squared_error: 0.5236\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4394 - mean_squared_error: 0.4394\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5214 - mean_squared_error: 0.5214\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4394 - mean_squared_error: 0.4394\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5220 - mean_squared_error: 0.5220\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4393 - mean_squared_error: 0.4393\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5170 - mean_squared_error: 0.5170\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4395 - mean_squared_error: 0.4395\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5276 - mean_squared_error: 0.5276\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4393 - mean_squared_error: 0.4393\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5227 - mean_squared_error: 0.5227\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4395 - mean_squared_error: 0.4395\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5279 - mean_squared_error: 0.5279\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4394 - mean_squared_error: 0.4394\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5216 - mean_squared_error: 0.5216\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4393 - mean_squared_error: 0.4393\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5277 - mean_squared_error: 0.5277\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4393 - mean_squared_error: 0.4393\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5195 - mean_squared_error: 0.5195\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4404 - mean_squared_error: 0.4404\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5249 - mean_squared_error: 0.5249\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4394 - mean_squared_error: 0.4394\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5221 - mean_squared_error: 0.5221\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4393 - mean_squared_error: 0.4393\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5208 - mean_squared_error: 0.5208\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4393 - mean_squared_error: 0.4393\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5239 - mean_squared_error: 0.5239\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4398 - mean_squared_error: 0.4398\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5208 - mean_squared_error: 0.5208\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4394 - mean_squared_error: 0.4394\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5233 - mean_squared_error: 0.5233\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4393 - mean_squared_error: 0.4393\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5193 - mean_squared_error: 0.5193\n",
            "(0.4395078748464584, 5.889699347420175e-05)\n",
            "(0.5230917433897654, 0.0005952023918760766)\n",
            "(array([ 0.69761765,  0.28008878, -0.15582432,  0.21069242,  0.29956415,\n",
            "       -0.26642978, -0.02551241,  0.28679562], dtype=float32), array([0.00103298, 0.00069953, 0.00076815, 0.00084409, 0.00072952,\n",
            "       0.00084301, 0.00079897, 0.00086109], dtype=float32))\n",
            "(2.465035, 0.0007592571326949232)\n"
          ]
        }
      ]
    }
  ]
}